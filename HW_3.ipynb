{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "r = re.compile(\"[а-яА-Я]+\")\n",
    "allWords = []\n",
    "dictionary = {}\n",
    "\n",
    "for i in range(129):\n",
    "    number = \"%(i)03d \"%{\"i\": i}\n",
    "    number = number[:-1]\n",
    "    f = open('/Users/sante/Выкачка'+number+'.txt', encoding=\"utf-8\")\n",
    "    for line in f:\n",
    "        tokens = tokenizer.tokenize(line)\n",
    "        filteredTokens = []\n",
    "        for token in tokens:\n",
    "            if token not in russian_stopwords:\n",
    "                filteredTokens.append(token)\n",
    "        russian = [w for w in filter(r.match, filteredTokens)]\n",
    "        for word in russian:\n",
    "            if len(word) > 1:\n",
    "                allWords.append(word)\n",
    "                if dictionary.get(word) is None:\n",
    "                    dictionary[word] = [number]\n",
    "                else:\n",
    "                    dictionary[word].append(number)\n",
    "                \n",
    "allWords = list(set(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = list(set(allWords))\n",
    "newDict = {}\n",
    "for word in allWords:\n",
    "     newDict[morph.parse(word)[0].normal_form] = []\n",
    "for word in allWords:\n",
    "    newDict[morph.parse(word)[0].normal_form].append(dictionary.get(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция объединяет n-мерный массив в одномерный\n",
    "def f(arr0):\n",
    "    arr1 = [] #создадим пустой массив\n",
    "    for i in arr0: #пройдёмся по всем элементам входного массива\n",
    "        if type(i) != list:\n",
    "            arr1.append(i) #если тип не list то в arr1 добавляем i\n",
    "        else:\n",
    "            arr1 += f(i) #иначе запускаем функцию для i\n",
    "    return arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemantize = open('invertedIndex.txt','w', encoding=\"utf-8\")\n",
    "for (key, value) in newDict.items():\n",
    "    res = list(set(f(value)))\n",
    "    newDict[morph.parse(word)[0].normal_form] = res\n",
    "    lemantize.write(key + \" \"  + \" \".join(res) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(встречающийся элемент, исключайющийся элемент, пересечние или объединение)\n",
    "def booleanSearch(containedElement, notContainedElemnt, isIntersection):\n",
    "    containedLinks = list(set(f(newDict[morph.parse(containedElement)[0].normal_form])))\n",
    "    allLinks = []\n",
    "    for i in range(129):\n",
    "        number = \"%(i)03d \"%{\"i\": i}\n",
    "        number = number[:-1]\n",
    "        allLinks.append(number)\n",
    "    notContainedLinks = allLinks.copy()\n",
    "    for link in list(set(f(newDict[morph.parse(notContainedElemnt)[0].normal_form]))):\n",
    "        notContainedLinks.remove(link)\n",
    "    res = []\n",
    "    if isIntersection:\n",
    "        res = [value for value in containedLinks if value in notContainedLinks]\n",
    "    else:\n",
    "        res = list(sorted(set(containedLinks + notContainedLinks)))\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '070', '071', '072', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '119', '120', '121', '122', '123', '124', '125', '126', '128']\n"
     ]
    }
   ],
   "source": [
    "booleanSearch(\"элегантный\", \"свита\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['031']\n"
     ]
    }
   ],
   "source": [
    "booleanSearch(\"элегантный\", \"свита\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
